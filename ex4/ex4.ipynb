{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "names目录下中存储了1880到2020年期间美国新生儿的姓名、出生年份、性别、出现次数等信息。请使用pandas处理数据，文件以txt形式存储，完成以下任务：\n",
    "\n",
    "1）统计数据集中男孩名字和女孩名字各有多少种；\n",
    "\n",
    "2）将数据集按照name字段进行分组，然后求和，赋值给变量names，最后输出前五行结果；\n",
    "\n",
    "3）按照每个名字被使用的次数（count）对第⼆步中结果进行降序排序，得出最受欢迎的五个名字；\n",
    "\n",
    "4）在数据集中，共出现了多少个不同的名字？（不包含重复项）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "男生名字有42567种,女生名字有68905种\n",
      "前五行的名字\n",
      "      Name  Count\n",
      "0    Aaban    120\n",
      "1    Aabha     46\n",
      "2    Aabid     16\n",
      "3  Aabidah      5\n",
      "4    Aabir     10\n",
      "前五多的名字\n",
      "          Name    Count\n",
      "39948    James  5213689\n",
      "44359     John  5163958\n",
      "77413   Robert  4849738\n",
      "65094  Michael  4405274\n",
      "95980  William  4159868\n",
      "共有100364个不同的名字\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设置文件路径\n",
    "file_directory = './names/'\n",
    "years = range(1880, 2021)  # year数据从1880-2020年\n",
    "all_data = []\n",
    "\n",
    "# 循环遍历所有文件，读取，并添加到一个列表中\n",
    "for year in years:\n",
    "    file_path = os.path.join(file_directory, f'yob{year}.txt')\n",
    "    \n",
    "    # 利用pandas定义列属性名\n",
    "    df_year = pd.read_csv(file_path, names=[\"Name\", \"Gender\", \"Count\"])\n",
    "    df_year['Year'] = year  # 另外添加一列year属性\n",
    "    all_data.append(df_year)\n",
    "\n",
    "# 将所有数据整合到同一个dataframe\n",
    "df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 1) 统计男孩和女孩的名字各有多少种\n",
    "num_boy_names = df[df['Gender'] == 'M']['Name'].nunique()\n",
    "num_girl_names = df[df['Gender'] == 'F']['Name'].nunique()\n",
    "\n",
    "# 2) 按name字段进行分组\n",
    "names = df.groupby(\"Name\").agg({\"Count\": \"sum\"}).reset_index()\n",
    "\n",
    "# 3) Sort by usage count and get the top 5 most popular names\n",
    "most_popular_5 = names.sort_values(by=\"Count\", ascending=False).head()\n",
    "\n",
    "# 4) Get the total number of unique names\n",
    "unique_names_count = df['Name'].nunique()\n",
    "\n",
    "print(f'男生名字有{num_boy_names}种,女生名字有{num_girl_names}种')\n",
    "print(f'前五行的名字\\n{names.head()}')\n",
    "print(f'前五多的名字\\n{most_popular_5}')\n",
    "print(f'共有{unique_names_count}个不同的名字')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "breast-cancer-wisconsin.data是⼀个医学数据集，包含了乳腺癌患者的诊断结果和相关指标，如：肿块大小、形状、边缘、质地、细胞核大小、细胞核形状等。该数据集共有11列，第1列为id，第2-10列为特征，第11列为标签（2为良性、4为恶性）。基于该数据集，完成以下任务：\n",
    "\n",
    "1）⼿动实现逻辑回归（除数据处理工具外不允许直接调用其他逻辑回归算法库）来进⾏癌症分类预测，具体实现方式可用梯度下降法；\n",
    "\n",
    "2）使用工具库，同样实现逻辑回归，并与手动实现的结果进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手动实现逻辑回归的准确率: 97.56%\n",
      "使用scikit-learn的逻辑回归准确率: 95.61%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 第一步：加载和预处理数据\n",
    "# 数据文件路径\n",
    "file_path = './breast-cancer-wisconsin.data'\n",
    "\n",
    "# 定义数据集的列名\n",
    "columns = ['id', 'clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity', \n",
    "           'marginal_adhesion', 'epithelial_cell_size', 'bare_nuclei', \n",
    "           'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class']\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(file_path, names=columns)\n",
    "\n",
    "# 替换缺失值（'?'）为NaN，然后丢弃含有NaN的行\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 将'bare_nuclei'列转换为整数类型（原始数据中由于存在缺失值导致其为字符串类型）\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype(int)\n",
    "\n",
    "# 分离特征和标签\n",
    "X = df.iloc[:, 1:-1].values  # 特征（第2-10列）\n",
    "y = df['class'].values  # 标签（第11列）\n",
    "\n",
    "# 将标签转换为二进制（2代表良性，转换为0；4代表恶性，转换为1）\n",
    "y = np.where(y == 2, 0, 1)\n",
    "\n",
    "# 标准化特征数据\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# 添加偏置项（在X的第一列添加全为1的列）\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "# 将数据划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 第二步：手动实现逻辑回归\n",
    "# 初始化逻辑回归的参数（权重和偏置）\n",
    "def sigmoid(z):\n",
    "    \"\"\"定义sigmoid函数\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_cost(X, y, theta):\n",
    "    \"\"\"定义损失函数（交叉熵损失）\"\"\"\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))  # 预测值\n",
    "    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))  # 计算损失\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"梯度下降算法\"\"\"\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # 计算预测值\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        # 更新权重\n",
    "        theta -= (alpha / m) * np.dot(X.T, h - y)\n",
    "        # 记录每次迭代的损失值\n",
    "        cost = compute_cost(X, y, theta)\n",
    "        cost_history.append(cost)\n",
    "    return theta, cost_history\n",
    "\n",
    "# 初始化参数\n",
    "theta = np.zeros(X_train.shape[1])  # 初始化theta为0\n",
    "alpha = 0.01  # 学习率\n",
    "num_iters = 100  # 迭代次数\n",
    "\n",
    "# 使用梯度下降算法训练模型\n",
    "theta_final, cost_history = gradient_descent(X_train, y_train, theta, alpha, num_iters)\n",
    "\n",
    "# 定义预测函数\n",
    "def predict(X, theta):\n",
    "    \"\"\"预测函数：返回0或1\"\"\"\n",
    "    return np.round(sigmoid(np.dot(X, theta)))\n",
    "\n",
    "# 使用手动实现的逻辑回归模型进行预测\n",
    "y_pred_manual = predict(X_test, theta_final)\n",
    "\n",
    "# 计算手动实现的逻辑回归模型的准确率\n",
    "accuracy_manual = np.mean(y_pred_manual == y_test) * 100\n",
    "print(f\"手动实现逻辑回归的准确率: {accuracy_manual:.2f}%\")\n",
    "\n",
    "# 第三步：使用工具库实现逻辑回归，并进行比较\n",
    "# 使用scikit-learn的LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train[:, 1:], y_train)  # 注意：工具库不需要偏置项，因此不包含X的第一列\n",
    "\n",
    "# 进行预测\n",
    "y_pred_sklearn = logreg.predict(X_test[:, 1:])\n",
    "\n",
    "# 计算scikit-learn实现的准确率\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn) * 100\n",
    "print(f\"使用scikit-learn的逻辑回归准确率: {accuracy_sklearn:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
